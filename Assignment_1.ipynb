{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import wandb\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,Y),(X_test,Y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m031\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/crysiswar999/Documents/GitHub/CS6910-Assignment-1/wandb/run-20230311_193345-xctm8ys5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/xctm8ys5' target=\"_blank\">examples of classes in fashion_mnist dataset</a></strong> to <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/xctm8ys5' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/xctm8ys5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(entity = 'cs22m031',project = 'CS6910_DL_assignment_1',name = 'examples of classes in fashion_mnist dataset')\n",
    "visited_label = []\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "class_images = []\n",
    "for x in range(len(X_test)):\n",
    "    if(Y_test[x] not in visited_label):\n",
    "        visited_label.append(Y_test[x])\n",
    "        image = wandb.Image(X_test[x],caption = class_names[Y_test[x]])\n",
    "        class_images.append(image)\n",
    "wandb.log({\"classes_examples\": class_images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(len(X),784,1)\n",
    "X[0].shape\n",
    "X_test = X_test.reshape(len(X_test),784,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,Y_train,Y_val = train_test_split(X,Y,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self,optimizer='nadam',batchsize=32,no_of_features = 784,no_of_classes = 10,no_of_layers=5,no_of_neurons_in_each_layer = [128,128,128],max_epochs = 10,eta = 0.001,initialization_method = 'he',activation_method = 'relu',loss = 'cross',weight_decay = 0.001):\n",
    "        self.optimizer  = optimizer\n",
    "        self.batchsize = batchsize\n",
    "        self.no_of_features = no_of_features\n",
    "        self.no_of_classes = no_of_classes\n",
    "        self.no_of_layers = no_of_layers\n",
    "        self.no_of_neurons_in_each_layer = no_of_neurons_in_each_layer\n",
    "        self.max_epochs = max_epochs\n",
    "        self.eta = eta\n",
    "        self.initialization = initialization_method\n",
    "        self.initialization_list = {'xavier':self.xavier_initialization,'uniform':self.uniform_initialization,'normal':self.normal_initialization,'he':self.he_initialization}\n",
    "        self.activation = activation_method\n",
    "        self.activation_list = {'sigmoid':self.sigmoid,'relu':self.Relu,'tanh':self.tanh}\n",
    "        self.activation_derivative = {'sigmoid':self.sigmoid_derivative,'relu':self.Relu_derivative,'tanh':self.tanh_derivative}\n",
    "        self.loss = loss\n",
    "        self.thetas = {}\n",
    "        self.loss_list = []\n",
    "        self.weight_decay = weight_decay\n",
    "    def one_hot(self,l,no_of_classes):\n",
    "        temp = np.array([0]*no_of_classes)\n",
    "        temp[l] = 1\n",
    "        return temp\n",
    "    def sigmoid(self,x):\n",
    "        return 1. / (1.+np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self,x):\n",
    "        return self.sigmoid(x) * (np.ones_like(x)-self.sigmoid(x))\n",
    "\n",
    "    def Relu(self,x):\n",
    "        for i in range(len(x)):\n",
    "            x[i] = x[i] / max(x[i])\n",
    "        return np.maximum(0,x)\n",
    "\n",
    "    def Relu_derivative(self,x):\n",
    "        # for i in range(len(x)):\n",
    "        #     x[i] = x[i] / max(x[i])\n",
    "        return 1*(x>0) \n",
    "\n",
    "    def tanh(self,x):\n",
    "        # for i in range(len(x)):\n",
    "        #     x[i] = x[i] / max(x[i])\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def tanh_derivative(self,x):\n",
    "        # for i in range(len(x)):\n",
    "        #     x[i] = x[i] / max(x[i])\n",
    "        return (1 - (np.tanh(x)**2))\n",
    "\n",
    "    def softmax(self,x):\n",
    "        # for i in range(len(x)):\n",
    "        #     x[i] = x[i] / max(x[i])\n",
    "        l = []\n",
    "        for i in range(len(x)):\n",
    "            l.append(np.exp(x[i])/np.sum(np.exp(x[i]),axis=0))\n",
    "        return np.array(l)\n",
    "        \n",
    "    def softmax_derivative(self,x):\n",
    "        # for i in range(len(x)):\n",
    "        #     x[i] = x[i] / max(x)\n",
    "        return self.softmax(x.reshape(1,x.shape[0],x.shape[1])) * (1-self.softmax(x.reshape(1,x.shape[0],x.shape[1])))\n",
    "\n",
    "\n",
    "\n",
    "    def he_initialization(self):\n",
    "        np.random.seed(42)\n",
    "        thetas = {}\n",
    "        for layer in range(1,self.no_of_layers):\n",
    "            if(layer == 1):\n",
    "                thetas['W'+str(layer)] = np.random.normal(0,1,size = (self.no_of_neurons_in_each_layer[layer-1],self.no_of_features)) * np.sqrt(2/(self.no_of_neurons_in_each_layer[layer-1]))\n",
    "                thetas['b'+str(layer)] = np.random.normal(0,1,size = (self.no_of_neurons_in_each_layer[layer-1],1))*np.sqrt(2/self.no_of_neurons_in_each_layer[layer-1])\n",
    "            elif(layer == self.no_of_layers-1):\n",
    "                thetas['W'+str(layer)] = np.random.normal(0,1,size = (self.no_of_classes,self.no_of_neurons_in_each_layer[layer-2])) * np.sqrt(2/(self.no_of_classes))\n",
    "                thetas['b'+str(layer)] = np.random.normal(0,1,size = (self.no_of_classes,1)) * np.sqrt(2/(self.no_of_classes))\n",
    "            else:\n",
    "                thetas['W'+str(layer)] = np.random.normal(0,1,size = (self.no_of_neurons_in_each_layer[layer-1],self.no_of_neurons_in_each_layer[layer-2])) * np.sqrt(2/(self.no_of_neurons_in_each_layer[layer-1]))\n",
    "                thetas['b'+str(layer)] = np.random.normal(0,1,size = (self.no_of_neurons_in_each_layer[layer-1],1)) * np.sqrt(2/self.no_of_neurons_in_each_layer[layer-1])\n",
    "        return thetas\n",
    "\n",
    "    def xavier_initialization(self):\n",
    "        np.random.seed(42)\n",
    "        thetas = {}\n",
    "        for layer in range(1,self.no_of_layers):\n",
    "            if(layer == 1):\n",
    "                thetas['W'+str(layer)] = np.random.randn(self.no_of_neurons_in_each_layer[layer-1],self.no_of_features) * np.sqrt(2/(self.no_of_neurons_in_each_layer[layer-1]+self.no_of_features))\n",
    "                thetas['b'+str(layer)] = np.zeros((self.no_of_neurons_in_each_layer[layer-1],1))\n",
    "            elif(layer == self.no_of_layers-1):\n",
    "                thetas['W'+str(layer)] = np.random.randn(self.no_of_classes,self.no_of_neurons_in_each_layer[layer-2]) * np.sqrt(2/(self.no_of_classes + self.no_of_neurons_in_each_layer[layer-2]))\n",
    "                thetas['b'+str(layer)] = np.zeros((self.no_of_classes,1))\n",
    "            else:\n",
    "                # print(layer)\n",
    "                # print(self.no_of_neurons_in_each_layer[layer-1])\n",
    "                # print(self.no_of_neurons_in_each_layer[layer-2])\n",
    "                thetas['W'+str(layer)] = np.random.randn(self.no_of_neurons_in_each_layer[layer-1],self.no_of_neurons_in_each_layer[layer-2]) * np.sqrt(2/(self.no_of_neurons_in_each_layer[layer-1]+self.no_of_neurons_in_each_layer[layer-2]))\n",
    "                thetas['b'+str(layer)] = np.zeros((self.no_of_neurons_in_each_layer[layer-1],1))\n",
    "        return thetas\n",
    "\n",
    "    def uniform_initialization(self):\n",
    "        thetas = {}\n",
    "        np.random.seed(42)\n",
    "        for layer in range(1,self.no_of_layers):\n",
    "            if(layer == 1):\n",
    "                thetas['W'+str(layer)] = np.random.default_rng().uniform(low = -0.7,high =0.7,size = (self.no_of_neurons_in_each_layer[layer-1],self.no_of_features)) #* np.sqrt(2/(no_of_neurons_in_each_layer[layer-1]+no_of_features))\n",
    "                thetas['b'+str(layer)] = np.random.default_rng().uniform(low = -0.7,high =0.7,size = (self.no_of_neurons_in_each_layer[layer-1],1))\n",
    "            elif(layer == self.no_of_layers-1):\n",
    "                thetas['W'+str(layer)] = np.random.default_rng().uniform(low = -0.7,high =0.7,size = (self.no_of_classes,self.no_of_neurons_in_each_layer[layer-2])) #* np.sqrt(2/(no_of_classes + no_of_neurons_in_each_layer[layer-2]))\n",
    "                thetas['b'+str(layer)] = np.random.default_rng().uniform(low = -0.7,high =0.7,size = (self.no_of_classes,1))\n",
    "            else:\n",
    "                thetas['W'+str(layer)] = np.random.default_rng().uniform(low = -0.7,high =0.7,size =(self.no_of_neurons_in_each_layer[layer-1],self.no_of_neurons_in_each_layer[layer-2])) #*  np.sqrt(2/(no_of_neurons_in_each_layer[layer-1]+no_of_neurons_in_each_layer[layer-2]))\n",
    "                thetas['b'+str(layer)] = np.random.default_rng().uniform(low = -0.7,high =0.7,size = (self.no_of_neurons_in_each_layer[layer-1],1))\n",
    "        return thetas\n",
    "\n",
    "    def normal_initialization(self):\n",
    "        thetas = {}\n",
    "        np.random.seed(42)\n",
    "        for layer in range(1,self.no_of_layers):\n",
    "            if(layer == 1):\n",
    "                thetas['W'+str(layer)] = np.random.uniform(low = -0.7,high =0.7,size = (self.no_of_neurons_in_each_layer[layer-1],self.no_of_features)) #* np.sqrt(2/(no_of_neurons_in_each_layer[layer-1]+no_of_features))\n",
    "                thetas['b'+str(layer)] = np.zeros((self.no_of_neurons_in_each_layer[layer-1],1))\n",
    "            elif(layer == self.no_of_layers-1):\n",
    "                thetas['W'+str(layer)] = np.random.uniform(low = -0.7,high =0.7,size = (self.no_of_classes,self.no_of_neurons_in_each_layer[layer-2])) #* np.sqrt(2/(no_of_classes + no_of_neurons_in_each_layer[layer-2]))\n",
    "                thetas['b'+str(layer)] = np.zeros((self.no_of_classes,1))\n",
    "            else:\n",
    "                thetas['W'+str(layer)] = np.random.uniform(low = -0.7,high =0.7,size =(self.no_of_neurons_in_each_layer[layer-1],self.no_of_neurons_in_each_layer[layer-2])) #*  np.sqrt(2/(no_of_neurons_in_each_layer[layer-1]+no_of_neurons_in_each_layer[layer-2]))\n",
    "                thetas['b'+str(layer)] = np.zeros((self.no_of_neurons_in_each_layer[layer-1],1))\n",
    "        return thetas\n",
    "\n",
    "    def feed_forward(self,data,thetas,layers):\n",
    "        pre_activation = [1]*(layers)\n",
    "        activation  = [1]*(layers)\n",
    "        activation[0] = data\n",
    "        for layer_no in range(1,layers):\n",
    "            W = 'W' + str(layer_no)\n",
    "            b = 'b' + str(layer_no)\n",
    "            pre_activation[layer_no] = np.add(np.matmul(thetas[W],activation[layer_no - 1]),thetas[b])\n",
    "            if(layer_no == layers-1):\n",
    "                activation[layer_no] = self.softmax(pre_activation[layer_no])\n",
    "            else:\n",
    "                activation[layer_no] = self.activation_list[self.activation](pre_activation[layer_no])\n",
    "        return activation,pre_activation\n",
    "\n",
    "    def back_propagate(self,h,a,thetas,Y):\n",
    "        grads = {}\n",
    "        for x in thetas.keys():\n",
    "            grads[x] = 0\n",
    "        for x in range(len(Y)):\n",
    "            temp = h[-1][x] - self.one_hot(Y[x],self.no_of_classes).reshape(self.no_of_classes,1)\n",
    "            if(self.loss == 'mse'):\n",
    "                temp = (temp*self.softmax_derivative(a[-1][x])).reshape(self.no_of_classes,1)\n",
    "            for k in range(self.no_of_layers-1,0,-1):\n",
    "                W = 'W' + str(k)\n",
    "                b = 'b' + str(k)\n",
    "                grads[W] += np.matmul(temp,h[k-1][x].T)/self.batchsize\n",
    "                grads[b] += temp/self.batchsize\n",
    "                if(k == 1):\n",
    "                    break\n",
    "                temp = np.matmul(thetas[W].T,temp)\n",
    "                temp = np.multiply(temp,self.activation_derivative[self.activation](a[k-1][x]))\n",
    "        return grads\n",
    "\n",
    "    def momentumUpdate(self,t,maxm=.999):\n",
    "        x=np.log(np.floor(t/250)+1)/np.log(2)\n",
    "        x=1-2**(-1-x)\n",
    "        return min(x,maxm)\n",
    "\n",
    "    def getGamma(self,epoch):\n",
    "        x=np.log((epoch/250)+1)\n",
    "        x=-1-1*(x)\n",
    "        x=2**x\n",
    "        x=1-x\n",
    "        return min(x,.9)\n",
    "\n",
    "    def fit(self,X_train,Y_train):\n",
    "        self.thetas = self.initialization_list[self.initialization]()\n",
    "        delta = 1e-9\n",
    "        grads = {}\n",
    "        for i in self.thetas.keys():\n",
    "            grads[i] = 0\n",
    "        for t in range(self.max_epochs):\n",
    "            #previous_update\n",
    "            ut = {}\n",
    "            vt = {}\n",
    "            gamma = self.getGamma(t+1)\n",
    "            beta = self.momentumUpdate(t+1)\n",
    "            for i in self.thetas.keys():\n",
    "                ut[i] = 0\n",
    "                vt[i] = 0\n",
    "            params_look_ahead = {}\n",
    "            step = 1\n",
    "            for x in range(0,X_train.shape[0],self.batchsize):\n",
    "                beta1 = 0.9#self.momentumUpdate(step)\n",
    "                beta2 = 0.99#self.momentumUpdate(step)\n",
    "                if(self.optimizer == 'nesterov'):\n",
    "                    for i in self.thetas.keys():\n",
    "                        params_look_ahead[i] = self.thetas[i] - beta1*ut[i]\n",
    "                    activation,preactivation = self.feed_forward(X_train[x:x+self.batchsize],self.thetas,self.no_of_layers)\n",
    "                    grads = self.back_propagate(activation,preactivation,params_look_ahead,Y_train[x:x+self.batchsize])\n",
    "                    for i in self.thetas.keys():\n",
    "                        ut[i] = beta1*ut[i] + (1-beta1)*grads[i]\n",
    "                        self.thetas[i] = self.thetas[i] - self.eta*ut[i] - self.eta*self.weight_decay*self.thetas[i]\n",
    "                elif(self.optimizer == 'mgd'):\n",
    "                    activation,preactivation = self.feed_forward(X_train[x:x+self.batchsize],self.thetas,self.no_of_layers)\n",
    "                    grads = self.back_propagate(activation,preactivation,self.thetas,Y_train[x:x+self.batchsize])     \n",
    "                    for i in self.thetas.keys():\n",
    "                        ut[i] = gamma*ut[i] + grads[i]\n",
    "                        self.thetas[i] = self.thetas[i] - self.eta*ut[i] - self.eta*self.weight_decay*self.thetas[i]\n",
    "                elif(self.optimizer == 'sgd'):\n",
    "                    activation,preactivation = self.feed_forward(X_train[x:x+self.batchsize],self.thetas,self.no_of_layers)\n",
    "                    grads = self.back_propagate(activation,preactivation,self.thetas,Y_train[x:x+self.batchsize])\n",
    "                    for i in self.thetas.keys():\n",
    "                        self.thetas[i] = self.thetas[i] - self.eta*grads[i] - self.eta*self.weight_decay*self.thetas[i]\n",
    "                elif(self.optimizer == 'RMSprop'):\n",
    "                    activation,preactivation = self.feed_forward(X_train[x:x+self.batchsize],self.thetas,self.no_of_layers)\n",
    "                    grads = self.back_propagate(activation,preactivation,self.thetas,Y_train[x:x+self.batchsize])\n",
    "                    for i in self.thetas.keys():\n",
    "                        ut[i] = beta*ut[i] + (1-beta)*np.multiply(grads[i],grads[i])\n",
    "                        self.thetas[i] = self.thetas[i] - self.eta*grads[i]/((np.sqrt(ut[i])+delta)) - self.eta*self.weight_decay*self.thetas[i]\n",
    "                elif(self.optimizer == 'adam'):\n",
    "                    activation,preactivation = self.feed_forward(X_train[x:x+self.batchsize],self.thetas,self.no_of_layers)\n",
    "                    grads = self.back_propagate(activation,preactivation,self.thetas,Y_train[x:x+self.batchsize])\n",
    "                    for i in self.thetas.keys():\n",
    "                        ut[i] = beta1*ut[i] + (1-beta1)*grads[i]\n",
    "                        uthat = ut[i]/(1 - pow(beta1,t+1))\n",
    "                        vt[i] = beta2*vt[i] + (1-beta2)*np.multiply(grads[i],grads[i])\n",
    "                        vthat = vt[i]/(1 - pow(beta2,t+1))\n",
    "                        self.thetas[i] = self.thetas[i] - self.eta*uthat/((np.sqrt(vthat) + delta)) - self.eta*self.weight_decay*self.thetas[i]\n",
    "                elif(self.optimizer == 'nadam'):\n",
    "                    activation,preactivation = self.feed_forward(X_train[x:x+self.batchsize],self.thetas,self.no_of_layers)\n",
    "                    grads = self.back_propagate(activation,preactivation,self.thetas,Y_train[x:x+self.batchsize])\n",
    "                    for i in self.thetas.keys():\n",
    "                        ut[i] = beta1*ut[i] + (1-beta1)*grads[i]\n",
    "                        uthat = ut[i]/(1 - pow(beta1,t+1))\n",
    "                        vt[i] = beta2*vt[i] + (1-beta2)*np.multiply(grads[i],grads[i])\n",
    "                        vthat = vt[i]/(1 - pow(beta2,t+1))\n",
    "                        self.thetas[i] = self.thetas[i] - (self.eta*(beta1*uthat + (1-beta1)*grads[i]/(1-pow(beta1,t+1))))/(np.sqrt(vthat) + delta) - self.eta*self.weight_decay*self.thetas[i]\n",
    "                step+=1\n",
    "            yhat = self.predict(X_train)\n",
    "            training_accuracy = self.accuracy_score(Y_train,yhat)\n",
    "            # print(training_accuracy)\n",
    "            training_loss = self.calculateLoss(yhat,Y_train)\n",
    "            # print(training_loss)\n",
    "            self.loss_list.append(training_loss)\n",
    "            yhat = self.predict(X_val)\n",
    "            validation_accuracy = self.accuracy_score(Y_val,yhat)\n",
    "            # print(validation_accuracy)\n",
    "            validation_loss = self.calculateLoss(yhat,Y_val)\n",
    "            # print(validation_loss)\n",
    "            wandb.log({'training_accuracy' : training_accuracy, 'validation_accuracy' : validation_accuracy,'training_loss' : training_loss, 'validation_loss' : validation_loss,'epoch':t+1})\n",
    "                \n",
    "    def predict(self,X):\n",
    "            activation,preactivation = self.feed_forward(X[:],self.thetas,self.no_of_layers)\n",
    "            return activation[-1]\n",
    "\n",
    "    def accuracy_score(self,Y,yhat):\n",
    "        correct = 0\n",
    "        for x in range(len(yhat)):\n",
    "            if(np.argmax(yhat[x]) == Y[x]):\n",
    "                correct+=1\n",
    "        return (correct/len(Y)*100)\n",
    "    def calculateLoss(self,yHat,yBatch):\n",
    "        loss=0\n",
    "        l2=0\n",
    "        if(self.loss == 'cross'):\n",
    "            for x in range(len(yHat)):\n",
    "                loss += (-1)*np.log(yHat[x][yBatch[x]] + 1e-9)\n",
    "            for x in self.thetas.keys():\n",
    "                l2 += np.linalg.norm(self.thetas[x])\n",
    "            l2 = (self.weight_decay*l2)/2\n",
    "            return (loss + l2)/len(yHat)\n",
    "        if(self.loss == 'mse'):\n",
    "                # error = (yHat-yBatch)\n",
    "                # error=error**2\n",
    "                # loss = np.sum(error,axis=0) \n",
    "                # loss = np.sum(error)  \n",
    "                # loss = loss/2\n",
    "            for x in range(len(yHat)):\n",
    "                loss += np.sum((self.one_hot(yBatch[x],self.no_of_classes).reshape(NN.no_of_classes,1) - yHat[x])**2,axis = 0)\n",
    "            for x in self.thetas.keys():\n",
    "                l2 += np.linalg.norm(self.thetas[x])\n",
    "            l2 = (self.weight_decay*l2)/2\n",
    "            return (loss[0] + l2)/len(yHat)\n",
    "        return loss\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    wandb.init(project='CS6910_DL_assignment_1')\n",
    "    config = wandb.config\n",
    "    wandb.run.name = \"op_{}_lr_{}_batch_{}_act_{}_layer_{}_neuron_{}\".format(config.optimizer ,config.eta,config.batchsize,config.activation,config.no_of_layers-2,config.no_of_neurons)\n",
    "    NN = NeuralNetwork(optimizer=config['optimizer'],batchsize=config['batchsize'],no_of_features=config['no_of_features'],no_of_classes=config['no_of_classes'],no_of_layers= config['no_of_layers'],no_of_neurons_in_each_layer = (config['no_of_layers']-2)*[config['no_of_neurons']],max_epochs=config['max_epochs'],eta = config['eta'],initialization_method=config['initialization'],activation_method=config['activation'],loss=config['loss'],weight_decay=config['weight_decay'])\n",
    "    NN.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: bim7ctyk\n",
      "Sweep URL: https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g241ryop with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teta: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_classes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_features: 784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_neurons: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: mgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/crysiswar999/Documents/GitHub/CS6910-Assignment-1/wandb/run-20230311_151734-g241ryop</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/g241ryop' target=\"_blank\">devoted-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/g241ryop' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/g241ryop</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>training_accuracy</td><td>▁▃▅▅▆▇▇███</td></tr><tr><td>training_loss</td><td>█▆▄▄▃▂▂▂▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▄▅▅▆▇▇███</td></tr><tr><td>validation_loss</td><td>█▆▄▄▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>training_accuracy</td><td>76.66481</td></tr><tr><td>training_loss</td><td>0.36311</td></tr><tr><td>validation_accuracy</td><td>76.31667</td></tr><tr><td>validation_loss</td><td>0.36929</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devoted-sweep-1</strong> at: <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/g241ryop' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/g241ryop</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230311_151734-g241ryop/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1f5z2eq8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teta: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_classes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_features: 784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_neurons: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/crysiswar999/Documents/GitHub/CS6910-Assignment-1/wandb/run-20230311_152101-1f5z2eq8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/1f5z2eq8' target=\"_blank\">summer-sweep-2</a></strong> to <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/1f5z2eq8' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/1f5z2eq8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>training_accuracy</td><td>▁▃▅▆▆▇▇███</td></tr><tr><td>training_loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>validation_loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>training_accuracy</td><td>88.85741</td></tr><tr><td>training_loss</td><td>0.16596</td></tr><tr><td>validation_accuracy</td><td>87.15</td></tr><tr><td>validation_loss</td><td>0.18655</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">summer-sweep-2</strong> at: <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/1f5z2eq8' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/1f5z2eq8</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230311_152101-1f5z2eq8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 13jjsliu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teta: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_classes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_features: 784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_layers: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_neurons: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: RMSprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/crysiswar999/Documents/GitHub/CS6910-Assignment-1/wandb/run-20230311_152400-13jjsliu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/13jjsliu' target=\"_blank\">comic-sweep-3</a></strong> to <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/13jjsliu' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/13jjsliu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>training_accuracy</td><td>▆█▇▄▁</td></tr><tr><td>training_loss</td><td>▁▄▆▇█</td></tr><tr><td>validation_accuracy</td><td>▇█▇▄▁</td></tr><tr><td>validation_loss</td><td>▁▄▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>training_accuracy</td><td>41.38889</td></tr><tr><td>training_loss</td><td>0.75485</td></tr><tr><td>validation_accuracy</td><td>40.25</td></tr><tr><td>validation_loss</td><td>0.75675</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comic-sweep-3</strong> at: <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/13jjsliu' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/13jjsliu</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230311_152400-13jjsliu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6x4i3iqi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teta: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_classes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_features: 784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_layers: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_neurons: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/crysiswar999/Documents/GitHub/CS6910-Assignment-1/wandb/run-20230311_152614-6x4i3iqi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/6x4i3iqi' target=\"_blank\">royal-sweep-4</a></strong> to <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/6x4i3iqi' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/6x4i3iqi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>training_accuracy</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>training_loss</td><td>█▅▃▃▂▂▂▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>validation_loss</td><td>█▅▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>training_accuracy</td><td>83.22593</td></tr><tr><td>training_loss</td><td>0.24477</td></tr><tr><td>validation_accuracy</td><td>82.15</td></tr><tr><td>validation_loss</td><td>0.25465</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">royal-sweep-4</strong> at: <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/6x4i3iqi' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/6x4i3iqi</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230311_152614-6x4i3iqi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4p788qvg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teta: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_classes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_features: 784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_neurons: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: mgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/crysiswar999/Documents/GitHub/CS6910-Assignment-1/wandb/run-20230311_152939-4p788qvg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/4p788qvg' target=\"_blank\">comfy-sweep-5</a></strong> to <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/sweeps/bim7ctyk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/4p788qvg' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/4p788qvg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>training_accuracy</td><td>▁▅▆▇█</td></tr><tr><td>training_loss</td><td>█▄▃▂▁</td></tr><tr><td>validation_accuracy</td><td>▁▅▆▇█</td></tr><tr><td>validation_loss</td><td>█▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>training_accuracy</td><td>71.32222</td></tr><tr><td>training_loss</td><td>0.39759</td></tr><tr><td>validation_accuracy</td><td>70.4</td></tr><tr><td>validation_loss</td><td>0.40807</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comfy-sweep-5</strong> at: <a href='https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/4p788qvg' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DL_assignment_1/runs/4p788qvg</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230311_152939-4p788qvg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sweep_configuration = {\n",
    "    'method' : 'bayes',\n",
    "    'metric' : { 'goal' : 'maximize',\n",
    "    'name' : 'validation_accuracy'},\n",
    "    'parameters':{\n",
    "        'optimizer' : { 'values' : ['sgd','mgd','nesterov','RMSprop','adam','nadam']},\n",
    "        'batchsize' : { 'values' : [16,32,64,128]},\n",
    "        'no_of_features' : {'values' : [784]},\n",
    "        'no_of_classes' : {'values' : [10]},\n",
    "        'no_of_layers' : { 'values' : [3,4,5,6]},\n",
    "        'no_of_neurons' : {'values' : [32,64,128]},\n",
    "        'max_epochs' : {'values' : [5,10]},\n",
    "        'eta' : { 'values' : [1e-1,1e-3,1e-4]},\n",
    "        'initialization' : { 'values' :['xavier','he','normal','uniform']},\n",
    "        'activation' : { 'values' : ['sigmoid','relu','tanh']},\n",
    "        'loss' : { 'values' : ['mse']},\n",
    "        'weight_decay'  : { 'values' : [0,0.0005,0.001]}\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep = sweep_configuration,project = 'CS6910_DL_assignment_1')\n",
    "wandb.agent(sweep_id,function=main,count = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_configuration = {\n",
    "    'method' : 'random',\n",
    "    'metric' : { 'goal' : 'maximize',\n",
    "    'name' : 'validation_accuracy'},\n",
    "    'parameters':{\n",
    "        'optimizer' : { 'values' : ['nadam']},\n",
    "        'batchsize' : { 'values' : [128]},\n",
    "        'no_of_features' : {'values' : [784]},\n",
    "        'no_of_classes' : {'values' : [10]},\n",
    "        'no_of_layers' : { 'values' : [5]},\n",
    "        'no_of_neurons' : {'values' : [256]},\n",
    "        'max_epochs' : {'values' : [5]},\n",
    "        'eta' : { 'values' : [0.001]},\n",
    "        'initialization' : { 'values' :['he']},\n",
    "        'activation' : { 'values' : ['relu']},\n",
    "        'loss' : { 'values' : ['mse']},\n",
    "        'weight_decay'  : { 'values' : [0,0.005,0.01]}\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep = sweep_configuration,project = 'CS6910_DL_assignment_1')\n",
    "wandb.agent(sweep_id,function=main,count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
