2023-03-09 17:22:54,213 INFO    Thread-6 (_run_job):18703 [wandb_setup.py:_flush():76] Configure stats pid to 18703
2023-03-09 17:22:54,213 INFO    Thread-6 (_run_job):18703 [wandb_setup.py:_flush():76] Loading settings from /Users/crysiswar999/.config/wandb/settings
2023-03-09 17:22:54,213 INFO    Thread-6 (_run_job):18703 [wandb_setup.py:_flush():76] Loading settings from /Users/crysiswar999/Documents/GitHub/CS6910-Assignment-1/wandb/settings
2023-03-09 17:22:54,213 INFO    Thread-6 (_run_job):18703 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'project': 'CS6910_DL_assignment_1', 'entity': 'cs22m031', 'root_dir': '/Users/crysiswar999/Documents/GitHub/CS6910-Assignment-1', 'sweep_id': 'w1ahfg63', 'run_id': '7u4p1mki', 'sweep_param_path': '/Users/crysiswar999/Documents/GitHub/CS6910-Assignment-1/wandb/sweep-w1ahfg63/config-7u4p1mki.yaml'}
2023-03-09 17:22:54,213 INFO    Thread-6 (_run_job):18703 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-03-09 17:22:54,213 INFO    Thread-6 (_run_job):18703 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-03-09 17:22:54,214 INFO    Thread-6 (_run_job):18703 [wandb_init.py:_log_setup():506] Logging user logs to /Users/crysiswar999/Documents/GitHub/CS6910-Assignment-1/wandb/run-20230309_172254-7u4p1mki/logs/debug.log
2023-03-09 17:22:54,214 INFO    Thread-6 (_run_job):18703 [wandb_init.py:_log_setup():507] Logging internal logs to /Users/crysiswar999/Documents/GitHub/CS6910-Assignment-1/wandb/run-20230309_172254-7u4p1mki/logs/debug-internal.log
2023-03-09 17:22:54,214 INFO    Thread-6 (_run_job):18703 [wandb_init.py:_jupyter_setup():452] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x28f3e82e0>
2023-03-09 17:22:54,215 INFO    Thread-6 (_run_job):18703 [wandb_init.py:init():546] calling init triggers
2023-03-09 17:22:54,215 INFO    Thread-6 (_run_job):18703 [wandb_init.py:init():552] wandb.init called with sweep_config: {'activation': 'tanh', 'batchsize': 128, 'eta': 0.001, 'initialization': 'normal', 'loss': 'cross', 'max_epochs': 10, 'no_of_classes': 10, 'no_of_features': 784, 'no_of_layers': 4, 'no_of_neurons': 64, 'optimizer': 'nesterov', 'weight_decay': 0}
config: {'_name': 'wandb.config', '__doc__': 'Config object.\n\n    Config objects are intended to hold all of the hyperparameters associated with\n    a wandb run and are saved with the run object when `wandb.init` is called.\n\n    We recommend setting `wandb.config` once at the top of your training experiment or\n    setting the config as a parameter to init, ie. `wandb.init(config=my_config_dict)`\n\n    You can create a file called `config-defaults.yaml`, and it will automatically be\n    loaded into `wandb.config`. See https://docs.wandb.com/guides/track/config#file-based-configs.\n\n    You can also load a config YAML file with your custom name and pass the filename\n    into `wandb.init(config="special_config.yaml")`.\n    See https://docs.wandb.com/guides/track/config#file-based-configs.\n\n    Examples:\n        Basic usage\n        ```\n        wandb.config.epochs = 4\n        wandb.init()\n        for x in range(wandb.config.epochs):\n            # train\n        ```\n\n        Using wandb.init to set config\n        ```\n        wandb.init(config={"epochs": 4, "batch_size": 32})\n        for x in range(wandb.config.epochs):\n            # train\n        ```\n\n        Nested configs\n        ```\n        wandb.config[\'train\'][\'epochs\'] = 4\n        wandb.init()\n        for x in range(wandb.config[\'train\'][\'epochs\']):\n            # train\n        ```\n\n        Using absl flags\n        ```\n        flags.DEFINE_string(‘model’, None, ‘model to run’) # name, default, help\n        wandb.config.update(flags.FLAGS) # adds all absl flags to config\n        ```\n\n        Argparse flags\n        ```python\n        wandb.init()\n        wandb.config.epochs = 4\n\n        parser = argparse.ArgumentParser()\n        parser.add_argument(\n            "-b",\n            "--batch-size",\n            type=int,\n            default=8,\n            metavar="N",\n            help="input batch size for training (default: 8)",\n        )\n        args = parser.parse_args()\n        wandb.config.update(args)\n        ```\n\n        Using TensorFlow flags (deprecated in tensorflow v2)\n        ```python\n        flags = tf.app.flags\n        flags.DEFINE_string("data_dir", "/tmp/data")\n        flags.DEFINE_integer("batch_size", 128, "Batch size.")\n        wandb.config.update(flags.FLAGS)  # adds all of the tensorflow flags to config\n        ```\n    '}
2023-03-09 17:22:54,215 INFO    Thread-6 (_run_job):18703 [wandb_init.py:init():602] starting backend
2023-03-09 17:22:54,215 INFO    Thread-6 (_run_job):18703 [wandb_init.py:init():606] setting up manager
2023-03-09 17:22:54,229 INFO    Thread-6 (_run_job):18703 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2023-03-09 17:22:54,239 INFO    Thread-6 (_run_job):18703 [wandb_init.py:init():613] backend started and connected
2023-03-09 17:22:54,248 INFO    Thread-6 (_run_job):18703 [wandb_run.py:_config_callback():1249] config_cb None None {'activation': 'tanh', 'batchsize': 128, 'eta': 0.001, 'initialization': 'normal', 'loss': 'cross', 'max_epochs': 10, 'no_of_classes': 10, 'no_of_features': 784, 'no_of_layers': 4, 'no_of_neurons': 64, 'optimizer': 'nesterov', 'weight_decay': 0}
2023-03-09 17:22:54,263 INFO    Thread-6 (_run_job):18703 [wandb_run.py:_label_probe_notebook():1202] probe notebook
2023-03-09 17:22:54,263 INFO    Thread-6 (_run_job):18703 [wandb_run.py:_label_probe_notebook():1212] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-03-09 17:22:54,263 INFO    Thread-6 (_run_job):18703 [wandb_init.py:init():701] updated telemetry
2023-03-09 17:22:54,296 INFO    Thread-6 (_run_job):18703 [wandb_init.py:init():741] communicating run to backend with 60.0 second timeout
2023-03-09 17:22:55,050 INFO    Thread-6 (_run_job):18703 [wandb_run.py:_on_init():2131] communicating current version
2023-03-09 17:22:55,135 INFO    Thread-6 (_run_job):18703 [wandb_run.py:_on_init():2140] got version response 
2023-03-09 17:22:55,135 INFO    Thread-6 (_run_job):18703 [wandb_init.py:init():789] starting run threads in backend
2023-03-09 17:22:55,215 INFO    Thread-6 (_run_job):18703 [wandb_run.py:_console_start():2112] atexit reg
2023-03-09 17:22:55,215 INFO    Thread-6 (_run_job):18703 [wandb_run.py:_redirect():1967] redirect: SettingsConsole.WRAP_RAW
2023-03-09 17:22:55,215 INFO    Thread-6 (_run_job):18703 [wandb_run.py:_redirect():2032] Wrapping output streams.
2023-03-09 17:22:55,216 INFO    Thread-6 (_run_job):18703 [wandb_run.py:_redirect():2057] Redirects installed.
2023-03-09 17:22:55,216 INFO    Thread-6 (_run_job):18703 [wandb_init.py:init():831] run started, returning control to user process
2023-03-09 17:24:51,163 INFO    Thread-6 (_run_job):18703 [wandb_run.py:_finish():1852] finishing run cs22m031/CS6910_DL_assignment_1/7u4p1mki
2023-03-09 17:24:51,164 INFO    Thread-6 (_run_job):18703 [jupyter.py:save_history():445] not saving jupyter history
2023-03-09 17:24:51,164 INFO    Thread-6 (_run_job):18703 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-03-09 17:24:51,164 INFO    Thread-6 (_run_job):18703 [wandb_init.py:_jupyter_teardown():434] cleaning up jupyter logic
2023-03-09 17:24:51,164 INFO    Thread-6 (_run_job):18703 [wandb_run.py:_atexit_cleanup():2081] got exitcode: 0
2023-03-09 17:24:51,165 INFO    Thread-6 (_run_job):18703 [wandb_run.py:_restore():2064] restore
2023-03-09 17:24:51,165 INFO    Thread-6 (_run_job):18703 [wandb_run.py:_restore():2070] restore done
2023-03-09 17:24:55,825 INFO    Thread-6 (_run_job):18703 [wandb_run.py:_footer_history_summary_info():3429] rendering history
2023-03-09 17:24:55,825 INFO    Thread-6 (_run_job):18703 [wandb_run.py:_footer_history_summary_info():3461] rendering summary
2023-03-09 17:24:55,828 INFO    Thread-6 (_run_job):18703 [wandb_run.py:_footer_sync_info():3387] logging synced files
