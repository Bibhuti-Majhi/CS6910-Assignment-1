2023-03-09 22:20:25,859 INFO    Thread-6 (_run_job):36515 [wandb_setup.py:_flush():76] Configure stats pid to 36515
2023-03-09 22:20:25,860 INFO    Thread-6 (_run_job):36515 [wandb_setup.py:_flush():76] Loading settings from /Users/crysiswar999/.config/wandb/settings
2023-03-09 22:20:25,860 INFO    Thread-6 (_run_job):36515 [wandb_setup.py:_flush():76] Loading settings from /Users/crysiswar999/Documents/GitHub/CS6910-Assignment-1/wandb/settings
2023-03-09 22:20:25,860 INFO    Thread-6 (_run_job):36515 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'project': 'CS6910_DL_assignment_1', 'entity': 'cs22m031', 'root_dir': '/Users/crysiswar999/Documents/GitHub/CS6910-Assignment-1', 'sweep_id': 'vib1plb5', 'run_id': 'vh11txtb', 'sweep_param_path': '/Users/crysiswar999/Documents/GitHub/CS6910-Assignment-1/wandb/sweep-vib1plb5/config-vh11txtb.yaml'}
2023-03-09 22:20:25,860 INFO    Thread-6 (_run_job):36515 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-03-09 22:20:25,860 INFO    Thread-6 (_run_job):36515 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-03-09 22:20:25,860 INFO    Thread-6 (_run_job):36515 [wandb_init.py:_log_setup():506] Logging user logs to /Users/crysiswar999/Documents/GitHub/CS6910-Assignment-1/wandb/run-20230309_222025-vh11txtb/logs/debug.log
2023-03-09 22:20:25,860 INFO    Thread-6 (_run_job):36515 [wandb_init.py:_log_setup():507] Logging internal logs to /Users/crysiswar999/Documents/GitHub/CS6910-Assignment-1/wandb/run-20230309_222025-vh11txtb/logs/debug-internal.log
2023-03-09 22:20:25,860 INFO    Thread-6 (_run_job):36515 [wandb_init.py:_jupyter_setup():452] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x156ba7340>
2023-03-09 22:20:25,861 INFO    Thread-6 (_run_job):36515 [wandb_init.py:init():546] calling init triggers
2023-03-09 22:20:25,861 INFO    Thread-6 (_run_job):36515 [wandb_init.py:init():552] wandb.init called with sweep_config: {'activation': 'relu', 'batchsize': 64, 'eta': 0.002, 'initialization': 'he', 'loss': 'cross', 'max_epochs': 5, 'no_of_classes': 10, 'no_of_features': 784, 'no_of_layers': 5, 'no_of_neurons': 256, 'optimizer': 'nadam', 'weight_decay': 0.001}
config: {'_name': 'wandb.config', '__doc__': 'Config object.\n\n    Config objects are intended to hold all of the hyperparameters associated with\n    a wandb run and are saved with the run object when `wandb.init` is called.\n\n    We recommend setting `wandb.config` once at the top of your training experiment or\n    setting the config as a parameter to init, ie. `wandb.init(config=my_config_dict)`\n\n    You can create a file called `config-defaults.yaml`, and it will automatically be\n    loaded into `wandb.config`. See https://docs.wandb.com/guides/track/config#file-based-configs.\n\n    You can also load a config YAML file with your custom name and pass the filename\n    into `wandb.init(config="special_config.yaml")`.\n    See https://docs.wandb.com/guides/track/config#file-based-configs.\n\n    Examples:\n        Basic usage\n        ```\n        wandb.config.epochs = 4\n        wandb.init()\n        for x in range(wandb.config.epochs):\n            # train\n        ```\n\n        Using wandb.init to set config\n        ```\n        wandb.init(config={"epochs": 4, "batch_size": 32})\n        for x in range(wandb.config.epochs):\n            # train\n        ```\n\n        Nested configs\n        ```\n        wandb.config[\'train\'][\'epochs\'] = 4\n        wandb.init()\n        for x in range(wandb.config[\'train\'][\'epochs\']):\n            # train\n        ```\n\n        Using absl flags\n        ```\n        flags.DEFINE_string(‘model’, None, ‘model to run’) # name, default, help\n        wandb.config.update(flags.FLAGS) # adds all absl flags to config\n        ```\n\n        Argparse flags\n        ```python\n        wandb.init()\n        wandb.config.epochs = 4\n\n        parser = argparse.ArgumentParser()\n        parser.add_argument(\n            "-b",\n            "--batch-size",\n            type=int,\n            default=8,\n            metavar="N",\n            help="input batch size for training (default: 8)",\n        )\n        args = parser.parse_args()\n        wandb.config.update(args)\n        ```\n\n        Using TensorFlow flags (deprecated in tensorflow v2)\n        ```python\n        flags = tf.app.flags\n        flags.DEFINE_string("data_dir", "/tmp/data")\n        flags.DEFINE_integer("batch_size", 128, "Batch size.")\n        wandb.config.update(flags.FLAGS)  # adds all of the tensorflow flags to config\n        ```\n    '}
2023-03-09 22:20:25,862 INFO    Thread-6 (_run_job):36515 [wandb_init.py:init():602] starting backend
2023-03-09 22:20:25,862 INFO    Thread-6 (_run_job):36515 [wandb_init.py:init():606] setting up manager
2023-03-09 22:20:25,875 INFO    Thread-6 (_run_job):36515 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2023-03-09 22:20:25,882 INFO    Thread-6 (_run_job):36515 [wandb_init.py:init():613] backend started and connected
2023-03-09 22:20:25,886 INFO    Thread-6 (_run_job):36515 [wandb_run.py:_config_callback():1249] config_cb None None {'activation': 'relu', 'batchsize': 64, 'eta': 0.002, 'initialization': 'he', 'loss': 'cross', 'max_epochs': 5, 'no_of_classes': 10, 'no_of_features': 784, 'no_of_layers': 5, 'no_of_neurons': 256, 'optimizer': 'nadam', 'weight_decay': 0.001}
2023-03-09 22:20:25,891 INFO    Thread-6 (_run_job):36515 [wandb_run.py:_label_probe_notebook():1202] probe notebook
2023-03-09 22:20:25,891 INFO    Thread-6 (_run_job):36515 [wandb_run.py:_label_probe_notebook():1212] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-03-09 22:20:25,892 INFO    Thread-6 (_run_job):36515 [wandb_init.py:init():701] updated telemetry
2023-03-09 22:20:25,920 INFO    Thread-6 (_run_job):36515 [wandb_init.py:init():741] communicating run to backend with 60.0 second timeout
2023-03-09 22:20:27,133 INFO    Thread-6 (_run_job):36515 [wandb_run.py:_on_init():2131] communicating current version
2023-03-09 22:20:28,241 INFO    Thread-6 (_run_job):36515 [wandb_run.py:_on_init():2140] got version response 
2023-03-09 22:20:28,242 INFO    Thread-6 (_run_job):36515 [wandb_init.py:init():789] starting run threads in backend
2023-03-09 22:20:28,319 INFO    Thread-6 (_run_job):36515 [wandb_run.py:_console_start():2112] atexit reg
2023-03-09 22:20:28,319 INFO    Thread-6 (_run_job):36515 [wandb_run.py:_redirect():1967] redirect: SettingsConsole.WRAP_RAW
2023-03-09 22:20:28,320 INFO    Thread-6 (_run_job):36515 [wandb_run.py:_redirect():2032] Wrapping output streams.
2023-03-09 22:20:28,320 INFO    Thread-6 (_run_job):36515 [wandb_run.py:_redirect():2057] Redirects installed.
2023-03-09 22:20:28,320 INFO    Thread-6 (_run_job):36515 [wandb_init.py:init():831] run started, returning control to user process
2023-03-09 22:31:23,670 INFO    Thread-6 (_run_job):36515 [wandb_run.py:_finish():1852] finishing run cs22m031/CS6910_DL_assignment_1/vh11txtb
2023-03-09 22:31:23,671 INFO    Thread-6 (_run_job):36515 [jupyter.py:save_history():445] not saving jupyter history
2023-03-09 22:31:23,671 INFO    Thread-6 (_run_job):36515 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-03-09 22:31:23,672 INFO    Thread-6 (_run_job):36515 [wandb_init.py:_jupyter_teardown():434] cleaning up jupyter logic
2023-03-09 22:31:23,672 INFO    Thread-6 (_run_job):36515 [wandb_run.py:_atexit_cleanup():2081] got exitcode: 0
2023-03-09 22:31:23,672 INFO    Thread-6 (_run_job):36515 [wandb_run.py:_restore():2064] restore
2023-03-09 22:31:23,672 INFO    Thread-6 (_run_job):36515 [wandb_run.py:_restore():2070] restore done
2023-03-09 22:31:29,600 INFO    Thread-6 (_run_job):36515 [wandb_run.py:_footer_history_summary_info():3429] rendering history
2023-03-09 22:31:29,601 INFO    Thread-6 (_run_job):36515 [wandb_run.py:_footer_history_summary_info():3461] rendering summary
2023-03-09 22:31:29,609 INFO    Thread-6 (_run_job):36515 [wandb_run.py:_footer_sync_info():3387] logging synced files
